<!DOCTYPE HTML>
<html lang="en">
<body style="background-color:whitesmoke;">

<head>
  <title>Sharath Chandra Raparthy</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Sharath Chandra Raparthy" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="http://localhost:4000/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>



<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>

                <font color=black>Sharath Chandra Raparthy</font>

              </h1>
              <p>I am a research intern at the <a href="https://mila.quebec/en/">Mila</a> working closely with  <a href="https://sites.google.com/site/irinarish/">Prof. Irina Rish.</a> Prior to this,
                I worked under the supervision of <a href="http://liampaull.ca/">Prof. Liam Paull</a>  at intersection of reinforcement learning and robotics.
              </p>
              <p>
                Previously, I worked with Prof. Calogero Maria Oddo, at <a href="https://www.santannapisa.it/en/neuro-robotic-touch-laboratory">Neuro-Robotic Touch Laboratory</a>  at <a href="https://www.santannapisa.it/it/istituto/biorobotica/biorobotics-institute">The BioRobotics Institute</a> , Italy, and with <a href="https://www.fose1.plymouth.ac.uk/torbjorn_dahl/index.html" >Prof. Torbjorn Dahl</a> at Plymouth University, United Kingdom, as a research intern. I also worked closely with a San Francisco based startup, <a href="https://www.gulukul.com/">Gulukul</a>, as a deep learning intern.
              </p>
              <p>
                I recently completed my undergraduate degree from <a href="http://vnit.ac.in/">Visvesvaraya National Institute of Technology</a> where I was a core co-ordinator at <a href="http://www.ivlabs.in/">IvLabs</a>, a robotics lab at VNIT.
              </p>
              <p>
                Besides research, I sometimes try to <a href="https://photos.app.goo.gl/Ry1TdoQ9EhJhYAcz8">capture random moments.</a>
              </p>
              <p style="text-align:center">
                <a target="_blank" href="sharathraparthy@gmail.com"> Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/SharathRaparthy">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.ca/citations?user=S1R0_UMAAAAJ&hl=en">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/sharath.jpg">
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0">
            <tbody>
                <tr>
                    <td style="padding-left:20px;">
                        <h2>Recent News</h2>
                    </td>

                </tr>
                <tr> <td style="padding-left:10px;">
                  <ul>
                    <li> <b> Feb 2020:</b> Our work CuNAS - CUriosity-driven Neural-Augmented Simulator has been accepted to <a href="https://sim2real.github.io/">Robotics: Science and Systems, Sim2Real workshop</a></li>
                    <li> <b> Feb 2020:</b> Our two works, <a href="https://arxiv.org/abs/2002.07911">SS-ADR</a> and <a href="https://arxiv.org/abs/2002.07956"> Meta-ADR</a> have been accepted to <a href="http://www.betr-rl.ml/2020/">ICLR BeTR-RL workshop</a>, Addis Ababa, Ethiopia</li>
                    <li> <b> Feb 2020:</b> Excited to announce two preprints: <a href="https://arxiv.org/abs/2002.07911">SS-ADR</a> and <a href="https://arxiv.org/abs/2002.07956"> Meta-ADR</a></li>
                    <li> <b> Feb 2020:</b> I will be joining <a href="https://mila.quebec/">Mila</a> as a Masters student in Fall 2020</li>
                  <li> <b> Jan 2020:</b> Started working with <a href="https://sites.google.com/site/irinarish/">Prof. Irina Rish</a> on Meta-Reinforcement Learning </li>
                   <li> <b> July 2019:</b> Attended and volunteered the multi-disciplinary conference on <a href="http://rldm.org/">Reinforcement Learning and Decision Making, RLDM-2019</a> </li>
                   <li><b> July 2019:</b> Started my internship at <a href="https://mila.quebec/">Montreal Institute for Learning Algorithms (Mila)</a> under <a href="http://liampaull.ca/">Prof. Liam Paull</a> </li>
                   <li><b> December 2018:</b> Our paper titled “Explicit Sequence Proximity Models for Hidden State Identification” is accepted to <a href="https://sites.google.com/site/rlponips2018/home/call-for-papers?authuser=0">
                  NeurIPS 2018 workshop on Reinforcement Learning under Partial Observability </a>  </li>
                   <li><b> October 2018:</b> I am happy to announce that I have been accepted for PyTorch Scholarship Challenge from Facebook. </li>
                  </ul>
            </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2><font color=black>Research</font></h2>
              <p>
                My research interest lies in the general area of Reinforcement Learning (RL), more specifically in meta-reinforcement learning (meta-RL) and continual learning.
              </p>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/neurips.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>CuNAS - CUriosity-driven Neural-Augmented Simulator</h3>
              <br>
              <strong>Sharath Chandra Raparthy</strong>, Melissa Mozifian, Liam Paull and Florian Golemo

              <br>
              <em>Robotics: Sicence and Systems; 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics</em>, 2020
              <br>
              
              <a href="">arxiv</a> /
              
              
              
              <a href="">code</a> /
              
              
              <p></p>
              <p>Transfer of policies from simulation to physical robots is an important open problem in deep reinforcement learning. Prior work has introduced the model-based Neural-Augmented Simulator (NAS) method, which uses task-independent data to create a model of the differences between simulated and real robot. In this work, we show that this method is sensitive to the sampling of motor actions and the control frequency. To overcome this problem, we propose a simple extension based on artificial curiosity. We demonstrate on a physical robot, that this leads to a better exploration of the state space and consequently better transfer performance when compared to the NAS baseline.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/unsup-adr.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Generating Automatic Curricula via Self-Supervised Active Domain Randomization </h3>
              <br>
              <strong>Sharath Chandra</strong>, Bhairav Mehta, Florian Golemo, Liam Paull

              <br>
              <em>Accepted to  ICLR BeTR-RL workshop. Submitted to International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2020
              <br>
              
              <a href="https://arxiv.org/abs/2002.07911">arxiv</a> /
              
              
              
              <a href="https://github.com/montrealrobotics/unsupervised-adr">code</a> /
              
              
              <a href="https://docs.google.com/presentation/d/1wy8jSWMQQtlwAtMIVtod0Z47ODXw9JvU4UskICPDPys/edit?usp=sharing">slides</a> /
              
              <p></p>
              <p>In  this work, we build on the framework of self-play, allowing an agent to interact with itself in order to make progress on some unknown task. We use Active  Domain  Randomization and self-play to create a novel, coupled environment-goal curriculum, where agents learn through progressively more difficult tasks and environment variations.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/meta-adr.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Curriculum in Gradient-Based Meta-Reinforcement Learning</h3>
              <br>
              Bhairav Mehta, Tristan Deleu*, <strong>Sharath Chandra*</strong> Christopher Pal, Liam Paull 

              <br>
              <em>Accepted to  ICLR BeTR-RL workshop. Submitted to Uncertainty in Artificial Intelligence (UAI)</em>, 2020
              <br>
              
              <a href="https://arxiv.org/abs/2002.07956">arxiv</a> /
              
              
              
              <a href="">code</a> /
              
              
              <p></p>
              <p>In this work we study the under-studied parameter in meta learning, “Task Distributions”. We show that Model Agnostic Meta-Learning (MAML) is sensitive to task distributions, and learning a curriculum of tasks instead of uniformly sampling helps the adaptation performance substantially.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/neurips.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Explicit Sequence Proximity Models for Hidden State Identification</h3>
              <br>
              Anil Kota, <strong>Sharath Chandra</strong>, Parag Khanna, Torbjorn Dahl

              <br>
              <em>Thirty-second Conference on Neural Information Processing Systems (NeurIPS), Workshop on Reinforcement Learning Under Partial Observability</em>, 2018
              <br>
              
              <a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/JoniPajarinen/RLPO2018_paper_20.pdf">arxiv</a> /
              
              
              
              <a href="https://github.com/SharathRaparthy/explicit_sequence_proximity">code</a> /
              
              
              <p></p>
              <p>We tackle the problem of hidden state identification in POMDPs. We show that more forgiving proximity models perform better than stricter models and that the difference between the models is more pronounced in the continuous navigation problem than in the discrete grid world problems.</p>

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Past Work</h2>
              <p>These include side projects and internships.
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/gulukul.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Gulukul</h3>
              <br>
              <em>Internship </em>
              <br>
              2018-07-10

              <br>
              
              
              
              
              
              
              
              
              
              
              <p></p>
              <p>The aim of the project is to transfer the motion between human subjects in different videos using  generative adversarial networks (GANs). We used an opensource implementation called OpenPose for detecting 2D pose keypoints for body, face and hand. We trained the GAN using google cloud virtual machine and used the architectures proposed in pix2pixHD paper.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/parloma.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>PARLOMA - Effective deaf-blind communication</h3>
              <br>
              <em>Internship  - Research under Prof. Calogero Maria Oddo at The BioRobotics Institute</em>
              <br>
              2018-06-10

              <br>
              
              
              
              
              
              
              <a href="https://drive.google.com/file/d/1f95u-EsrvohqberHLO1XBdQUw72VisZE/view">video</a> /
              
              
              
              
              <a href="https://drive.google.com/file/d/0BzxxKJtl3b_wR3AzbTMwQXl2bUU/view">report</a> /
              
              
              <p></p>
              <p>This work aims at designing a remote communication system for deaf-blind people where we focus on implementing state-of-the-art algorithms for 3d hand pose estimation using different approaches like deep learning, semi-supervised learning and random forest classifier. It involves the integration of haptic and robotic interfaces together with CNN based approaches for hand pose estimation and remote reproduction of tactile sign language (t-SL) by using one 3D printed bio-mimetic robotic hand.</p>

            </td>
          </tr>
          
          
          
          
          
          
          
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Mentorship</h2>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/ivlabs.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>IvLabs</h3>
              <br>
              <em>Mentorship </em>
<!--              <br>-->
<!--              2016-07-24-->

<!--              <br>-->
              
              
              
              
              
              
              
              
              
              
              <p></p>
              <p>I am a former core committee member of <a href="http://www.ivlabs.in/">IvLabs</a>. I have been actively mentoring some <a href="https://akshayk07.weebly.com/">motivated</a> <a href="https://github.com/navidpanchi">students</a> on their projects.</p>

            </td>
          </tr>
          
          
          
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
               Of course, I didn't build this from scratch. Source stolen from  <a style="font-size:small;" href="https://jonbarron.info">here</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

